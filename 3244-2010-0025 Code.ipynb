{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "data_dir = \"../3244-2010-0025 Project/\"\n",
    "parasite = os.listdir('Parasitized/') \n",
    "uninfected = os.listdir('Uninfected/')\n",
    "parasite.remove(\"Thumbs.db\")               #databse file in both folders\n",
    "uninfected.remove(\"Thumbs.db\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "df_para, label_para = [], [] \n",
    "\n",
    "\n",
    "\n",
    "for filename in parasite:\n",
    "    img = load_img(data_dir + \"Parasitized/\" + filename, target_size = (50, 50)) #Images resized to 50x50x3\n",
    "    i = img_to_array(img)\n",
    "    samples = expand_dims(i, 0)\n",
    "    for j in range(2):\n",
    "        datagen = ImageDataGenerator(rotation_range=360, fill_mode='nearest')   #Add 2 randomly rotated images from original\n",
    "        aug_iter = datagen.flow(samples, batch_size=1)\n",
    "        \n",
    "        image = aug_iter.next()[0].astype('uint8')\n",
    "        df_para.append(image)\n",
    "    \n",
    "    df_para.append(i)                          \n",
    "    for i in range(3):\n",
    "        label_para.append(1)        \n",
    "    \n",
    "df_un, label_un = [],[]            \n",
    "\n",
    "for filename in uninfected:\n",
    "    img = load_img(data_dir + \"Uninfected/\" + filename, target_size = (50, 50))\n",
    "    i = img_to_array(img)\n",
    "    samples = expand_dims(i, 0)\n",
    "    for j in range(2):\n",
    "        datagen = ImageDataGenerator(rotation_range=360, fill_mode='nearest')\n",
    "        aug_iter = datagen.flow(samples, batch_size=1)\n",
    "        \n",
    "        image = aug_iter.next()[0].astype('uint8')\n",
    "        df_un.append(image)\n",
    "    df_un.append(i)                          \n",
    "    for i in range(3):\n",
    "        label_un.append(0)                            #label is a column of labels, 1 = parasitised, 0 = uninfected\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = df_para + df_un\n",
    "labels = label_para + label_un\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "images = images/255              #scaling the values so that they are between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"images\",images)  #Saved the arrays to remove the need for reading imeages from files again\n",
    "np.save(\"labels\",labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training and test arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras import optimizers\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import keras as keras\n",
    "images = np.load(\"images.npy\")\n",
    "labels = np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "Splitting the data into training, validation and test sets. X_train_full is the complete training set to be used on test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score\n",
    "np.random.seed(10)\n",
    "X_train_full, X_test, y_train_full, y_test = sk.model_selection.train_test_split(images, labels, \n",
    "                                                                     test_size = 0.2, random_state = 10)\n",
    "\n",
    "#Further split training dataset into training and validation\n",
    "X_train, X_val, y_train, y_val = sk.model_selection.train_test_split(X_train_full, y_train_full, \n",
    "                                                                     test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Models\n",
    "### Perceptron Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(tol = None, max_iter = 1000,random_state=10,early_stopping=True,verbose=1)\n",
    "mlp_X_train = np.array(X_train).reshape((-1,50*50*3))     #Reshape tensors to vectors \n",
    "mlp_y_train = np.array(y_train)\n",
    "clf.fit(mlp_X_train,mlp_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLA Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, precision_score,recall_score\n",
    "y_true = np.array(y_val)\n",
    "y_pred = clf.predict(np.array(X_val).reshape((-1,7500)))\n",
    "print(confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None))\n",
    "print(\"Accuracy is \",accuracy_score(y_true, y_pred))\n",
    "print(\"F1-Score is \",f1_score(y_true, y_pred))\n",
    "print(\"Precision is \",precision_score(y_true, y_pred))\n",
    "print(\"Recall is \",recall_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "LRmodel = LogisticRegression(random_state=10,max_iter=1000).fit(mlp_X_train, mlp_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, precision_score,recall_score\n",
    "y_true = np.array(y_val)\n",
    "y_pred = LRmodel.predict(np.array(X_val).reshape((-1,7500)))\n",
    "print(confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None))\n",
    "print(\"Accuracy is \",accuracy_score(y_true, y_pred))\n",
    "print(\"F1-Score is \",f1_score(y_true, y_pred))\n",
    "print(\"Precision is \",precision_score(y_true, y_pred))\n",
    "print(\"Recall is \",recall_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplified VGG-16(Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "basemodel = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Dense(512, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "basemodel.compile( optimizer=optimizers.SGD(lr = 1e-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "basehistory = basemodel.fit(X_train, y_train,validation_data=(X_val,y_val), epochs=40, batch_size=32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base VGG-16 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_val\n",
    "y_pred = basemodel.predict_classes(X_val)\n",
    "print(confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None))\n",
    "print(\"Accuracy is \",accuracy_score(y_true, y_pred))\n",
    "print(\"F1-Score is \",f1_score(y_true, y_pred))\n",
    "print(\"Precision is \",precision_score(y_true, y_pred))\n",
    "print(\"Recall is \",recall_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmbase = confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "print(cmbase[0][1]/(cmbase[0][1]+cmbase[0][0])) #FPR\n",
    "print(cmbase[1][0]/(cmbase[1][0]+cmbase[1][1])) #FNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperas Experiments\n",
    "This section takes a very long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperas\n",
    "\n",
    "#When running Hyperas we cant access global variables so need to save numpy arrays locally first\n",
    "np.save('images.npy', images)\n",
    "np.save('labels.npy', labels)\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "def data():\n",
    "    import numpy as np\n",
    "    import sklearn as sk\n",
    "    from sklearn.model_selection import train_test_split\n",
    " \n",
    "    images = np.load('images.npy')\n",
    "    labels = np.load('labels.npy') \n",
    "\n",
    "    X_train, X_val, y_train, y_val = sk.model_selection.train_test_split(images, labels, test_size = 0.2, random_state = np.random)\n",
    "    X_train = X_train/255\n",
    "    X_val= X_val/255\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "def model(X_train, y_train, X_val, y_val):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same', input_shape = (50, 50, 3)))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "   \n",
    "    model.add(Conv2D(128, (3, 3), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "   \n",
    "    model.add(Dense({{choice([1024, 2048, 4096])}}, activation = 'relu'))\n",
    "    model.add(Dense({{choice([1024, 2048, 4096])}}, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = {{choice(['sigmoid', 'softmax'])}})) #or model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "    adam = keras.optimizers.Adam(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "    rmsprop = keras.optimizers.RMSprop(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "    sgd = keras.optimizers.SGD(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "    adamax = keras.optimizers.Adamax(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "    nadam = keras.optimizers.Nadam(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "   \n",
    "    choiceval = {{choice(['adam', 'rmsprop', 'sgd', 'adamax', 'nadam'])}}\n",
    "    if choiceval == 'adam':\n",
    "        optim = adam\n",
    "    elif choiceval == 'rmsprop':\n",
    "        optim = rmsprop\n",
    "    elif choiceval == 'sgd':\n",
    "        optim = sgd\n",
    "    elif choiceval == 'adamax':\n",
    "        optim = adamax\n",
    "    else:\n",
    "        optim = nadam\n",
    "        \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optim, metrics = ['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size = {{choice([16, 32, 50, 64])}},\n",
    "              epochs= {{choice([10, 20, 50])}},\n",
    "              verbose = 2,\n",
    "              validation_data = (X_val, y_val))\n",
    "    score, acc = model.evaluate(X_val, y_val, verbose = 0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "#print(\"Tuning hyperparams\")\n",
    "\n",
    "X_train, y_train, X_val, y_val = data()\n",
    "\n",
    "best_run, best_model = optim.minimize(model = model,\n",
    "                                      data = data,\n",
    "                                      algo = tpe.suggest,\n",
    "                                      max_evals = 30,\n",
    "                                      trials = Trials())\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on Optimisers\n",
    "### RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.17),\n",
    "    \n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "model.compile( optimizer=optimizers.RMSprop(lr = 1e-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "historyrms = model.fit(X_train, y_train,validation_data=(X_val,y_val), epochs=20, batch_size=64)\n",
    "np.save('historyrms.npy',historyrms.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.17),\n",
    "    \n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "\n",
    "model.compile( optimizer=optimizers.Nadam(lr = 1e-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "historynadam = model.fit(X_train, y_train,validation_data=(X_val,y_val), epochs=20, batch_size=64)\n",
    "np.save('historynadam.npy',historynadam.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.17),\n",
    "    \n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "#chg optimizer accordingly SGD,RMSprop,Adam,Adadelta,Adagrad,Adamax,Nadam,Ftrl\n",
    "\n",
    "model.compile( optimizer=optimizers.Adamax(lr = 1e-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "historyadamax= model.fit(X_train, y_train,validation_data=(X_val,y_val), epochs=20, batch_size=64)\n",
    "np.save('historyadamax.npy',historyadamax.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.17),\n",
    "    \n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "#chg optimizer accordingly SGD,RMSprop,Adam,Adadelta,Adagrad,Adamax,Nadam,Ftrl\n",
    "\n",
    "\n",
    "model.compile( optimizer=optimizers.Adam(lr = 1e-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "historyadam= model.fit(X_train, y_train,validation_data=(X_val,y_val), epochs=20, batch_size=64)\n",
    "np.save('historyadam.npy',historyadam.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.17),\n",
    "    \n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "#chg optimizer accordingly SGD,RMSprop,Adam,Adadelta,Adagrad,Adamax,Nadam,Ftrl\n",
    "\n",
    "model.compile( optimizer=optimizers.SGD(lr = 1e-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "historysgd = model.fit(X_train, y_train,validation_data=(X_val,y_val), epochs=20, batch_size=64)\n",
    "np.save('historysgd.npy',historysgd.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.17),\n",
    "    \n",
    "    keras.layers.Dense(128, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "#chg optimizer accordingly SGD,RMSprop,Adam,Adadelta,Adagrad,Adamax,Nadam,Ftrl\n",
    "model.compile( optimizer=optimizers.Adadelta(lr = 1e-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "historyadadelta = model.fit(X_train, y_train,validation_data=(X_val,y_val), epochs=20, batch_size=64)\n",
    "np.save('historyadadelta.npy',historyadadelta.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting validation loss over epochs for each optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historysgd=np.load('historysgd.npy',allow_pickle='TRUE').item()              #Load the histories\n",
    "historyrms=np.load('historyrms.npy',allow_pickle='TRUE').item()\n",
    "historyadam=np.load('historyadam.npy',allow_pickle='TRUE').item()\n",
    "historynadam=np.load('historynadam.npy',allow_pickle='TRUE').item()\n",
    "historyadamax=np.load('historyadamax.npy',allow_pickle='TRUE').item()\n",
    "historyadadelta=np.load('historyadadelta.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.title(\"val_loss\")\n",
    "plt.plot(historysgd['val_loss'],'-b',label=\"sgd\")\n",
    "plt.plot(historyrms['val_loss'],'-g',label=\"rms\")\n",
    "plt.plot(historyadam['val_loss'],'-r',label=\"adam\")\n",
    "plt.plot(historynadam['val_loss'],'-o',label=\"nadam\")\n",
    "plt.plot(historyadamax['val_loss'],'-y',label=\"adamax\")\n",
    "plt.plot(historyadadelta['val_loss'],'-p',label=\"adadelta\")\n",
    "plt.legend(fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of weights on FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = 4 #Repeated for 2,4,6,8,10\n",
    "from keras import optimizers\n",
    "baseweightedmodel = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Dense(512, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "baseweightedmodel.compile( optimizer=optimizers.SGD(lr = 1e-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "baseweightedmodel.fit(X_train, y_train,validation_data=(X_val,y_val), epochs=20, batch_size=32, class_weight={0:1,1:wt}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, precision_score,recall_score\n",
    "y_true = y_val\n",
    "y_pred = baseweightedmodel.predict_classes(X_val)\n",
    "print(confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None))\n",
    "print(\"Accuracy is \",accuracy_score(y_true, y_pred))\n",
    "print(\"F1-Score is \",f1_score(y_true, y_pred))\n",
    "print(\"Precision is \",precision_score(y_true, y_pred))\n",
    "print(\"Recall is \",recall_score(y_true, y_pred))\n",
    "cmweightedbase = confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "#print(cmbase[0][1]/(cmbase[0][1]+cmbase[0][0])) #FPR\n",
    "print(cmweightedbase[1][0]/(cmweightedbase[1][0]+cmweightedbase[1][1])) #FNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of number of VGG-16 layers on accuracy\n",
    "Here we try out the different layers of VGG-16 to see if they achieve better results\n",
    "### 7 layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Layers VGG (Our simplified model)\n",
    "model = Sequential([\n",
    "\n",
    "    #1st stack\n",
    "    Conv2D(32, (3, 3), padding='same', activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    #Conv2D(32, (3, 3), padding='same', activation= 'relu'), \n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #2nd stack\n",
    "    Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #3rd stack\n",
    "    Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #4th stack\n",
    "    Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #5th stack\n",
    "    Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128, activation = 'relu'),\n",
    "    #Dense(128, activation = 'relu'), \n",
    "    Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "    \n",
    "model.compile( optimizer=optimizers.RMSprop(lr = 10**-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "history = model.fit(X_train, y_train, validation_data = (X_val,y_val), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_val\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None))\n",
    "print(\"Accuracy is \",accuracy_score(y_true, y_pred))\n",
    "print(\"F1-Score is \",f1_score(y_true, y_pred))\n",
    "print(\"Precision is \",precision_score(y_true, y_pred))\n",
    "print(\"Recall is \",recall_score(y_true, y_pred))\n",
    "cmbase = confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "print(cmbase[0][1]/(cmbase[0][1]+cmbase[0][0])) #FPR\n",
    "print(cmbase[1][0]/(cmbase[1][0]+cmbase[1][1])) #FNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#12 Layers VGG\n",
    "model = Sequential([\n",
    "\n",
    "    #1st stack\n",
    "    Conv2D(32, (3, 3), padding='same', activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    Conv2D(32, (3, 3), padding='same', activation= 'relu'), \n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #2nd stack\n",
    "    Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #3rd stack\n",
    "    Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #4th stack\n",
    "    Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #5th stack\n",
    "    Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(128, activation = 'relu'),\n",
    "    #Dense(128, activation = 'relu'), \n",
    "    Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "    \n",
    "model.compile( optimizer=optimizers.RMSprop(lr = 10**-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "history = model.fit(X_train, y_train, validation_data = (X_val,y_val), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, precision_score,recall_score\n",
    "y_true = y_val\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None))\n",
    "print(\"Accuracy is \",accuracy_score(y_true, y_pred))\n",
    "print(\"F1-Score is \",f1_score(y_true, y_pred))\n",
    "print(\"Precision is \",precision_score(y_true, y_pred))\n",
    "print(\"Recall is \",recall_score(y_true, y_pred))\n",
    "cmbase = confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "print(cmbase[0][1]/(cmbase[0][1]+cmbase[0][0])) #FPR\n",
    "print(cmbase[1][0]/(cmbase[1][0]+cmbase[1][1])) #FNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16 layer (Full VGG-16) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16 Layers VGG (Full model)\n",
    "model = Sequential([\n",
    "\n",
    "    #1st stack\n",
    "    Conv2D(32, (3, 3), padding='same', activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    Conv2D(32, (3, 3), padding='same', activation= 'relu'), \n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #2nd stack\n",
    "    Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #3rd stack\n",
    "    Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #4th stack\n",
    "    Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #5th stack\n",
    "    Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(128, activation = 'relu'), \n",
    "    Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "    \n",
    "model.compile( optimizer=optimizers.RMSprop(lr = 10**-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "history = model.fit(X_train, y_train, validation_data = (X_val,y_val), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, precision_score,recall_score\n",
    "y_true = y_val\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None))\n",
    "print(\"Accuracy is \",accuracy_score(y_true, y_pred))\n",
    "print(\"F1-Score is \",f1_score(y_true, y_pred))\n",
    "print(\"Precision is \",precision_score(y_true, y_pred))\n",
    "print(\"Recall is \",recall_score(y_true, y_pred))\n",
    "cmbase = confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "print(cmbase[0][1]/(cmbase[0][1]+cmbase[0][0])) #FPR\n",
    "print(cmbase[1][0]/(cmbase[1][0]+cmbase[1][1])) #FNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with pre-trained VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is using Keras' VGG16 architecture via transfer learning\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = VGG16(weights = 'imagenet', include_top = False, input_shape = (50, 50, 3))\n",
    "base_model = Model(inputs = base_model.input, outputs = base_model.get_layer('block5_conv2').output)\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = MaxPooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "#Add a logistic layer \n",
    "predictions = Dense(1, activation = 'sigmoid', name = 'predictions')(x)\n",
    "\n",
    "#This is the model we will train\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 10**-3), loss = 'binary_crossentropy', metrics = ['accuracy','AUC'])\n",
    "history = model.fit(X_train, y_train, validation_data = (X_val,y_val), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, precision_score,recall_score\n",
    "y_true = y_val\n",
    "y_pred = np.around(model.predict(X_val))\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None))\n",
    "print(\"Accuracy is \",accuracy_score(y_true, y_pred))\n",
    "print(\"F1-Score is \",f1_score(y_true, y_pred))\n",
    "print(\"Precision is \",precision_score(y_true, y_pred))\n",
    "print(\"Recall is \",recall_score(y_true, y_pred))\n",
    "cmbase = confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "print(cmbase[0][1]/(cmbase[0][1]+cmbase[0][0])) #FPR\n",
    "print(cmbase[1][0]/(cmbase[1][0]+cmbase[1][1])) #FNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Modified VGG-16 model\n",
    "We run the final model as well as the base model with the full training set and test their performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalmodel = keras.Sequential([\n",
    "\n",
    "    #1st stack\n",
    "    Conv2D(32, (3, 3), padding='same', activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    Conv2D(32, (3, 3), padding='same', activation= 'relu'), \n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #2nd stack\n",
    "    Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #3rd stack\n",
    "    Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #4th stack\n",
    "    Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    #5th stack\n",
    "    Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    #Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "    #Dropout(0.5), #Can try without dropout\n",
    "    \n",
    "    Dense(128, activation = 'relu'),\n",
    "    #Dense(128, activation = 'relu'), \n",
    "    Dense(1, activation = 'sigmoid') \n",
    "    \n",
    "    ])\n",
    "\n",
    "finalmodel.compile( optimizer=optimizers.SGD(lr = 1e-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "history = finalmodel.fit(X_train_full, y_train_full,validation_data=(X_val,y_val), epochs=40, batch_size=32,class_weight={0:1,1:4}) #weight = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = pd.DataFrame(finalmodel.predict_classes(X_test))\n",
    "errordf = pd.concat([ypred,pd.DataFrame(y_test)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, precision_score,recall_score\n",
    "y_true = y_test\n",
    "y_pred = finalmodel.predict_classes(X_test)\n",
    "finalcmbase= confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "print(confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None))\n",
    "print(\"Accuracy is \",accuracy_score(y_true, y_pred))\n",
    "print(\"F1-Score is \",f1_score(y_true, y_pred))\n",
    "print(\"Precision is \",precision_score(y_true, y_pred))\n",
    "print(\"Recall is \",recall_score(y_true, y_pred))\n",
    "print(finalcmbase[0][1]/(finalcmbase[0][1]+finalcmbase[0][0])) #FPR\n",
    "print(finalcmbase[1][0]/(finalcmbase[1][0]+finalcmbase[1][1])) #FNR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model with weighted penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "basemodel = keras.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (50, 50, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Dense(512, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    ])\n",
    "basemodel.compile( optimizer=optimizers.SGD(lr = 1e-3),loss='binary_crossentropy', metrics=['accuracy','AUC'])\n",
    "basehistory = basemodel.fit(X_train_full, y_train_full,validation_data=(X_val,y_val), epochs=40, batch_size=32,class_weight={0:1,1:4}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score, f1_score, precision_score,recall_score\n",
    "y_true = y_test\n",
    "y_pred = basemodel.predict_classes(X_test)\n",
    "cmbase= confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "print(confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None))\n",
    "print(\"Accuracy is \",accuracy_score(y_true, y_pred))\n",
    "print(\"F1-Score is \",f1_score(y_true, y_pred))\n",
    "print(\"Precision is \",precision_score(y_true, y_pred))\n",
    "print(\"Recall is \",recall_score(y_true, y_pred))\n",
    "print(cmbase[0][1]/(cmbase[0][1]+cmbase[0][0])) #FPR\n",
    "print(cmbase[1][0]/(cmbase[1][0]+cmbase[1][1])) #FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = pd.DataFrame(basemodel.predict_classes(X_test))\n",
    "errordf = pd.concat([ypred,pd.DataFrame(y_test)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to find out how off is the predicted labels from actual labels\n",
    "\n",
    "import matplotlib.pyplot as pltpy\n",
    "\n",
    "predictions = (finalmodel.predict(X_test) > 0.5).astype(int).flatten()\n",
    "wrong_predictions = finalmodel.predict(X_test)[predictions != y_test]\n",
    "wrong_pred_list = []\n",
    "for i in range(wrong_predictions.shape[0]):\n",
    "    wrong_pred_list.append(wrong_predictions[i][0])\n",
    "\n",
    "fn_list_pre = []\n",
    "fp_list_pre = []\n",
    "\n",
    "for i in range(len(wrong_pred_list)):\n",
    "        if wrong_pred_list[i] >= 0.5:\n",
    "            fp_list_pre.append(wrong_pred_list[i])\n",
    "        else:\n",
    "            fn_list_pre.append(wrong_pred_list[i])\n",
    "\n",
    "fn_list = []\n",
    "fp_list = []\n",
    "            \n",
    "for i in range(len(fn_list_pre)):\n",
    "    fn_list.append(0.5 - fn_list_pre[i])\n",
    "    \n",
    "for i in range(len(fp_list_pre)):\n",
    "    fp_list.append(fp_list_pre[i] - 0.5)\n",
    "    \n",
    "pltpy.hist(fn_list, bins = 20)     #False negative distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltpy.hist(fp_list, bins = 20)  #False positive distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying False Negative and False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False Negatives and False Positives of Final Model\n",
    "ypredfinal = pd.DataFrame(finalmodel.predict_classes(X_test))\n",
    "errordffinal = pd.concat([ypred,pd.DataFrame(y_test)],axis=1)\n",
    "ypredbase = pd.DataFrame(basemodel.predict_classes(X_test))\n",
    "errordfbase = pd.concat([ypred,pd.DataFrame(y_test)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "misclassified = errordffinal[errordffinal.iloc[:,0] != errordffinal.iloc[:,1]]\n",
    "FP = misclassified[misclassified.iloc[:,0]==1]\n",
    "FN = misclassified[misclassified.iloc[:,0]==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive for Final VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,5))\n",
    "for i in range(1,11):\n",
    "    plt.subplot(2,5,i)\n",
    "    plt.imshow(X_test[FP.index[i]])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Negatives for Final VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(1,11):\n",
    "    plt.subplot(2,5,i)\n",
    "    plt.imshow(X_test[FN.index[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassified Images for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False negatives and false positives of LogReg\n",
    "y_true = np.array(y_val)\n",
    "y_pred = LRmodel.predict(np.array(X_val).reshape((-1,7500)))\n",
    "ypred = pd.DataFrame(y_pred)\n",
    "errordf = pd.concat([ypred,pd.DataFrame(y_true)],axis=1)\n",
    "\n",
    "misclassified = errordf[errordf.iloc[:,0] != errordf.iloc[:,1]]\n",
    "FP = misclassified[misclassified.iloc[:,0]==1]\n",
    "FN = misclassified[misclassified.iloc[:,0]==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positives for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False Positives\n",
    "plt.title(\"False Positives\")\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(1,11):\n",
    "    plt.title()\n",
    "    plt.subplot(2,5,i)\n",
    "    plt.imshow(X_test.reshape((-1,50,50,3))[FP.index[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Negatives for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False Negatives\n",
    "plt.title(\"False Negatives\")\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(1,11):\n",
    "    plt.subplot(2,5,i)\n",
    "    plt.imshow(X_test.reshape((-1,50,50,3))[FN.index[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassified Images for PLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False positives and negatives for PLA\n",
    "y_true = np.array(y_val)\n",
    "y_pred = clf.predict(np.array(X_val).reshape((-1,7500)))\n",
    "ypred = pd.DataFrame(y_pred)\n",
    "errordf = pd.concat([ypred,pd.DataFrame(y_true)],axis=1)\n",
    "\n",
    "misclassified = errordf[errordf.iloc[:,0] != errordf.iloc[:,1]]\n",
    "FP = misclassified[misclassified.iloc[:,0]==1]\n",
    "FN = misclassified[misclassified.iloc[:,0]==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positives for PLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False Positives\n",
    "plt.title(\"False Positives\")\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(1,11):\n",
    "    plt.title()\n",
    "    plt.subplot(2,5,i)\n",
    "    plt.imshow(X_test.reshape((-1,50,50,3))[FP.index[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Negatives for PLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False Negatives\n",
    "plt.title(\"False Negatives\")\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(1,11):\n",
    "    plt.subplot(2,5,i)\n",
    "    plt.imshow(X_test.reshape((-1,50,50,3))[FN.index[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
